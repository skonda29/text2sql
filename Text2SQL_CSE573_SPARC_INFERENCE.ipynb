{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73a4e2762ee4448b8a5feb0b63918970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6667b5ffb7ae4a14bfe8b2311890742a",
              "IPY_MODEL_d919a2f84cf64abdbad57115cb2ac630",
              "IPY_MODEL_411ca5d60e3d4a4e8337b2c931482a2b"
            ],
            "layout": "IPY_MODEL_7fb8d4066ddd48e38abc8011d8746e8e"
          }
        },
        "6667b5ffb7ae4a14bfe8b2311890742a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b792570aea94912a416a3f99dd0110b",
            "placeholder": "​",
            "style": "IPY_MODEL_c3a9a38007154ab09d122546993ddfee",
            "value": "Batches: 100%"
          }
        },
        "d919a2f84cf64abdbad57115cb2ac630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b9315e182e049c3ac1d508a7118bc85",
            "max": 169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fcc45fa3f9a4949abe86faf9785bb64",
            "value": 169
          }
        },
        "411ca5d60e3d4a4e8337b2c931482a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63e1c8a5ddb843d1aabe3b74035077b6",
            "placeholder": "​",
            "style": "IPY_MODEL_aad41fcd3976479389812ec7d28e7140",
            "value": " 169/169 [00:01&lt;00:00, 140.25it/s]"
          }
        },
        "7fb8d4066ddd48e38abc8011d8746e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b792570aea94912a416a3f99dd0110b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3a9a38007154ab09d122546993ddfee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b9315e182e049c3ac1d508a7118bc85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fcc45fa3f9a4949abe86faf9785bb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63e1c8a5ddb843d1aabe3b74035077b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad41fcd3976479389812ec7d28e7140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa77dcb1d570472b8741aac08a5cd5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe6379e0c59f464e9e61421ac0036245",
              "IPY_MODEL_21f05c9243b340a283c68b5c44ed32e5",
              "IPY_MODEL_a50180e2ed5e422987930592c01542dc"
            ],
            "layout": "IPY_MODEL_d8e82091c4fd49eeb4b16818d8d640aa"
          }
        },
        "fe6379e0c59f464e9e61421ac0036245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9aa61c61ddc4b55910f3e7cefb7619c",
            "placeholder": "​",
            "style": "IPY_MODEL_5b78530836b54fa7bda2cc5d3868073d",
            "value": "Batches: 100%"
          }
        },
        "21f05c9243b340a283c68b5c44ed32e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecdf64d7faf94cbb9bdef16a0943fbab",
            "max": 169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10ab10ba7cc945a5ad60f16fb1f6f6d5",
            "value": 169
          }
        },
        "a50180e2ed5e422987930592c01542dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae3a9599f91048f59e921a81ae67c241",
            "placeholder": "​",
            "style": "IPY_MODEL_3b07e2895f794a53b00a1107a276803c",
            "value": " 169/169 [00:01&lt;00:00, 122.79it/s]"
          }
        },
        "d8e82091c4fd49eeb4b16818d8d640aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9aa61c61ddc4b55910f3e7cefb7619c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b78530836b54fa7bda2cc5d3868073d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecdf64d7faf94cbb9bdef16a0943fbab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ab10ba7cc945a5ad60f16fb1f6f6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae3a9599f91048f59e921a81ae67c241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b07e2895f794a53b00a1107a276803c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TEXT2SQL USING LLAMA 3.1 8B**"
      ],
      "metadata": {
        "id": "C6SAHdaisGNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentence-transformers faiss-cpu accelerate numpy tqdm groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XbIGQEIqvXBm",
        "outputId": "cd942665-7967-4c0c-e776-9d8988fbaed5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting groq\n",
            "  Downloading groq-0.37.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.37.0-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu, groq\n",
            "Successfully installed faiss-cpu-1.13.0 groq-0.37.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "15uqrDKOPk4_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Embeddings / LLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from groq import Groq # Import Groq\n",
        "\n",
        "# Vector DB\n",
        "import faiss  # pip install faiss-cpu\n",
        "\n",
        "# Neo4j\n",
        "#from neo4j import GraphDatabase  # pip install neo4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkC2a_pPzf-N",
        "outputId": "7a361658-74e6-4898-8ab6-6b4d9856905d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CONFIG\n",
        "# ============================================================\n",
        "\n",
        "TABLES_JSON_PATH = \"./tables.json\"  # path to Spider/SParC-style tables.json\n",
        "NEO4J_URI = \"bolt://localhost:7687\"\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"password\"\n",
        "\n",
        "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "# Flan-T5 model fine-tuned on Spider / SParC / CoSQL (SQL task)\n",
        "# We'll reuse it with a TRC-style prompt.\n",
        "FLAN_T5_MODEL_NAME = \"alpecevit/flan-t5-base-text2sql\""
      ],
      "metadata": {
        "id": "GDLkulA6QAPp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SCHEMA DATA CLASSES\n",
        "# ============================================================\n",
        "\n",
        "@dataclass\n",
        "class ColumnSchema:\n",
        "    col_id: int\n",
        "    table_id: int\n",
        "    name: str\n",
        "    orig_name: str\n",
        "    col_type: str\n",
        "\n",
        "@dataclass\n",
        "class TableSchema:\n",
        "    table_id: int\n",
        "    name: str\n",
        "    orig_name: str\n",
        "    columns: List[ColumnSchema] = field(default_factory=list)\n",
        "    primary_keys: List[int] = field(default_factory=list)      # list of col_ids\n",
        "    foreign_keys: List[Tuple[int, int]] = field(default_factory=list)  # (src_col_id, dst_col_id)\n",
        "\n",
        "@dataclass\n",
        "class DatabaseSchema:\n",
        "    db_id: str\n",
        "    tables: Dict[int, TableSchema] = field(default_factory=dict)        # table_id -> TableSchema\n",
        "    columns: Dict[int, ColumnSchema] = field(default_factory=dict)      # col_id   -> ColumnSchema"
      ],
      "metadata": {
        "id": "uG4PTooxQXrW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 1: LOAD SCHEMA FROM SPARC/SPIDER TABLES.JSON\n",
        "# ============================================================\n",
        "\n",
        "def load_spider_like_tables_json(path: str) -> Dict[str, DatabaseSchema]:\n",
        "    \"\"\"\n",
        "    Load Spider/SParC 'tables.json' into a structured dict of DatabaseSchema.\n",
        "\n",
        "    tables.json format (per Spider/SParC docs):\n",
        "      - db_id\n",
        "      - table_names, table_names_original\n",
        "      - column_names, column_names_original\n",
        "      - column_types\n",
        "      - primary_keys  (list of column indices)\n",
        "      - foreign_keys  (list of [src_col_idx, dst_col_idx])\n",
        "    \"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw = json.load(f)\n",
        "\n",
        "    db_schemas: Dict[str, DatabaseSchema] = {}\n",
        "\n",
        "    for db_meta in raw:\n",
        "        db_id = db_meta[\"db_id\"]\n",
        "        table_names = db_meta[\"table_names\"]\n",
        "        table_names_original = db_meta[\"table_names_original\"]\n",
        "        column_names = db_meta[\"column_names\"]\n",
        "        column_names_original = db_meta[\"column_names_original\"]\n",
        "        column_types = db_meta[\"column_types\"]\n",
        "        primary_keys = db_meta[\"primary_keys\"]\n",
        "        foreign_keys = db_meta[\"foreign_keys\"]\n",
        "\n",
        "        db_schema = DatabaseSchema(db_id=db_id)\n",
        "\n",
        "        # Create table schemas\n",
        "        for table_id, (name, orig_name) in enumerate(zip(table_names, table_names_original)):\n",
        "            db_schema.tables[table_id] = TableSchema(\n",
        "                table_id=table_id,\n",
        "                name=name,\n",
        "                orig_name=orig_name,\n",
        "            )\n",
        "\n",
        "        # Create column schemas\n",
        "        for col_id, ((table_id, col_name), (_, col_orig_name), col_type) in enumerate(\n",
        "            zip(column_names, column_names_original, column_types)\n",
        "        ):\n",
        "            if table_id == -1:\n",
        "                # This is the \"dummy\" column (for * in some preprocessing setups).\n",
        "                continue\n",
        "            col_schema = ColumnSchema(\n",
        "                col_id=col_id,\n",
        "                table_id=table_id,\n",
        "                name=col_name,\n",
        "                orig_name=col_orig_name,\n",
        "                col_type=col_type,\n",
        "            )\n",
        "            db_schema.columns[col_id] = col_schema\n",
        "            db_schema.tables[table_id].columns.append(col_schema)\n",
        "\n",
        "        # Attach primary keys\n",
        "        for pk_col_id in primary_keys:\n",
        "            if pk_col_id in db_schema.columns:\n",
        "                col = db_schema.columns[pk_col_id]\n",
        "                db_schema.tables[col.table_id].primary_keys.append(pk_col_id)\n",
        "\n",
        "        # Attach foreign keys\n",
        "        for src_col_id, dst_col_id in foreign_keys:\n",
        "            if src_col_id in db_schema.columns and dst_col_id in db_schema.columns:\n",
        "                src_col = db_schema.columns[src_col_id]\n",
        "                db_schema.tables[src_col.table_id].foreign_keys.append((src_col_id, dst_col_id))\n",
        "\n",
        "        db_schemas[db_id] = db_schema\n",
        "\n",
        "    return db_schemas\n"
      ],
      "metadata": {
        "id": "wYwyNSs-Q04O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 2: BUILD NEO4J GRAPH (TABLE, COLUMN, EDGES)\n",
        "# ============================================================\n",
        "'''\n",
        "class SchemaGraphBuilder:\n",
        "    def __init__(self, uri: str, user: str, password: str):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "\n",
        "    def clear_database(self):\n",
        "        with self.driver.session() as session:\n",
        "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
        "\n",
        "    def build_graph(self, db_schemas: Dict[str, DatabaseSchema]):\n",
        "        \"\"\"\n",
        "        Build:\n",
        "          (:TABLE {db_id, table_id, name})\n",
        "          (:COLUMN {db_id, col_id, table_id, name, col_type})\n",
        "          (:TABLE)-[:HAS_COLUMN]->(:COLUMN)\n",
        "          (:COLUMN)-[:PRIMARY_KEY_OF]->(:TABLE)\n",
        "          (:COLUMN)-[:FOREIGN_KEY_TO]->(:COLUMN)\n",
        "          (:TABLE)-[:JOINS_WITH]->(:TABLE)\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            for db_id, db_schema in tqdm(db_schemas.items(), desc=\"Building Neo4j schema graph\"):\n",
        "                # TABLE and COLUMN nodes + HAS_COLUMN\n",
        "                for table in db_schema.tables.values():\n",
        "                    session.run(\n",
        "                        \"\"\"\n",
        "                        MERGE (t:TABLE {db_id:$db_id, table_id:$table_id})\n",
        "                        SET t.name = $name, t.orig_name = $orig_name\n",
        "                        \"\"\",\n",
        "                        db_id=db_id,\n",
        "                        table_id=table.table_id,\n",
        "                        name=table.name,\n",
        "                        orig_name=table.orig_name,\n",
        "                    )\n",
        "                    for col in table.columns:\n",
        "                        session.run(\n",
        "                            \"\"\"\n",
        "                            MERGE (c:COLUMN {db_id:$db_id, col_id:$col_id})\n",
        "                            SET c.name = $name,\n",
        "                                c.orig_name = $orig_name,\n",
        "                                c.col_type = $col_type,\n",
        "                                c.table_id = $table_id\n",
        "                            WITH c\n",
        "                            MATCH (t:TABLE {db_id:$db_id, table_id:$table_id})\n",
        "                            MERGE (t)-[:HAS_COLUMN]->(c)\n",
        "                            \"\"\",\n",
        "                            db_id=db_id,\n",
        "                            table_id=table.table_id,\n",
        "                            col_id=col.col_id,\n",
        "                            name=col.name,\n",
        "                            orig_name=col.orig_name,\n",
        "                            col_type=col.col_type,\n",
        "                        )\n",
        "\n",
        "                # PRIMARY_KEY_OF edges\n",
        "                for table in db_schema.tables.values():\n",
        "                    for pk_col_id in table.primary_keys:\n",
        "                        if pk_col_id not in db_schema.columns:\n",
        "                            continue\n",
        "                        session.run(\n",
        "                            \"\"\"\n",
        "                            MATCH (c:COLUMN {db_id:$db_id, col_id:$col_id}),\n",
        "                                  (t:TABLE {db_id:$db_id, table_id:$table_id})\n",
        "                            MERGE (c)-[:PRIMARY_KEY_OF]->(t)\n",
        "                            \"\"\",\n",
        "                            db_id=db_id,\n",
        "                            col_id=pk_col_id,\n",
        "                            table_id=table.table_id,\n",
        "                        )\n",
        "\n",
        "                # FOREIGN_KEY_TO and JOINS_WITH edges\n",
        "                for table in db_schema.tables.values():\n",
        "                    for src_col_id, dst_col_id in table.foreign_keys:\n",
        "                        if src_col_id not in db_schema.columns or dst_col_id not in db_schema.columns:\n",
        "                            continue\n",
        "                        src_col = db_schema.columns[src_col_id]\n",
        "                        dst_col = db_schema.columns[dst_col_id]\n",
        "                        src_table_id = src_col.table_id\n",
        "                        dst_table_id = dst_col.table_id\n",
        "                        session.run(\n",
        "                            \"\"\"\n",
        "                            MATCH (src:COLUMN {db_id:$db_id, col_id:$src_col_id}),\n",
        "                                  (dst:COLUMN {db_id:$db_id, col_id:$dst_col_id})\n",
        "                            MERGE (src)-[:FOREIGN_KEY_TO]->(dst)\n",
        "                            \"\"\",\n",
        "                            db_id=db_id,\n",
        "                            src_col_id=src_col_id,\n",
        "                            dst_col_id=dst_col_id,\n",
        "                        )\n",
        "                        # JOINS_WITH in both directions\n",
        "                        session.run(\n",
        "                            \"\"\"\n",
        "                            MATCH (t1:TABLE {db_id:$db_id, table_id:$t1_id}),\n",
        "                                  (t2:TABLE {db_id:$db_id, table_id:$t2_id})\n",
        "                            MERGE (t1)-[:JOINS_WITH]->(t2)\n",
        "                            MERGE (t2)-[:JOINS_WITH]->(t1)\n",
        "                            \"\"\",\n",
        "                            db_id=db_id,\n",
        "                            t1_id=src_table_id,\n",
        "                            t2_id=dst_table_id,\n",
        "                        )\n",
        "'''"
      ],
      "metadata": {
        "id": "xh6bUhmtcODE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "cbaa0e26-1ae6-4ec5-dc60-7b0db845115f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass SchemaGraphBuilder:\\n    def __init__(self, uri: str, user: str, password: str):\\n        self.driver = GraphDatabase.driver(uri, auth=(user, password))\\n\\n    def close(self):\\n        self.driver.close()\\n\\n    def clear_database(self):\\n        with self.driver.session() as session:\\n            session.run(\"MATCH (n) DETACH DELETE n\")\\n\\n    def build_graph(self, db_schemas: Dict[str, DatabaseSchema]):\\n        \"\"\"\\n        Build:\\n          (:TABLE {db_id, table_id, name})\\n          (:COLUMN {db_id, col_id, table_id, name, col_type})\\n          (:TABLE)-[:HAS_COLUMN]->(:COLUMN)\\n          (:COLUMN)-[:PRIMARY_KEY_OF]->(:TABLE)\\n          (:COLUMN)-[:FOREIGN_KEY_TO]->(:COLUMN)\\n          (:TABLE)-[:JOINS_WITH]->(:TABLE)\\n        \"\"\"\\n        with self.driver.session() as session:\\n            for db_id, db_schema in tqdm(db_schemas.items(), desc=\"Building Neo4j schema graph\"):\\n                # TABLE and COLUMN nodes + HAS_COLUMN\\n                for table in db_schema.tables.values():\\n                    session.run(\\n                        \"\"\"\\n                        MERGE (t:TABLE {db_id:$db_id, table_id:$table_id})\\n                        SET t.name = $name, t.orig_name = $orig_name\\n                        \"\"\",\\n                        db_id=db_id,\\n                        table_id=table.table_id,\\n                        name=table.name,\\n                        orig_name=table.orig_name,\\n                    )\\n                    for col in table.columns:\\n                        session.run(\\n                            \"\"\"\\n                            MERGE (c:COLUMN {db_id:$db_id, col_id:$col_id})\\n                            SET c.name = $name,\\n                                c.orig_name = $orig_name,\\n                                c.col_type = $col_type,\\n                                c.table_id = $table_id\\n                            WITH c\\n                            MATCH (t:TABLE {db_id:$db_id, table_id:$table_id})\\n                            MERGE (t)-[:HAS_COLUMN]->(c)\\n                            \"\"\",\\n                            db_id=db_id,\\n                            table_id=table.table_id,\\n                            col_id=col.col_id,\\n                            name=col.name,\\n                            orig_name=col.orig_name,\\n                            col_type=col.col_type,\\n                        )\\n\\n                # PRIMARY_KEY_OF edges\\n                for table in db_schema.tables.values():\\n                    for pk_col_id in table.primary_keys:\\n                        if pk_col_id not in db_schema.columns:\\n                            continue\\n                        session.run(\\n                            \"\"\"\\n                            MATCH (c:COLUMN {db_id:$db_id, col_id:$col_id}),\\n                                  (t:TABLE {db_id:$db_id, table_id:$table_id})\\n                            MERGE (c)-[:PRIMARY_KEY_OF]->(t)\\n                            \"\"\",\\n                            db_id=db_id,\\n                            col_id=pk_col_id,\\n                            table_id=table.table_id,\\n                        )\\n\\n                # FOREIGN_KEY_TO and JOINS_WITH edges\\n                for table in db_schema.tables.values():\\n                    for src_col_id, dst_col_id in table.foreign_keys:\\n                        if src_col_id not in db_schema.columns or dst_col_id not in db_schema.columns:\\n                            continue\\n                        src_col = db_schema.columns[src_col_id]\\n                        dst_col = db_schema.columns[dst_col_id]\\n                        src_table_id = src_col.table_id\\n                        dst_table_id = dst_col.table_id\\n                        session.run(\\n                            \"\"\"\\n                            MATCH (src:COLUMN {db_id:$db_id, col_id:$src_col_id}),\\n                                  (dst:COLUMN {db_id:$db_id, col_id:$dst_col_id})\\n                            MERGE (src)-[:FOREIGN_KEY_TO]->(dst)\\n                            \"\"\",\\n                            db_id=db_id,\\n                            src_col_id=src_col_id,\\n                            dst_col_id=dst_col_id,\\n                        )\\n                        # JOINS_WITH in both directions\\n                        session.run(\\n                            \"\"\"\\n                            MATCH (t1:TABLE {db_id:$db_id, table_id:$t1_id}),\\n                                  (t2:TABLE {db_id:$db_id, table_id:$t2_id})\\n                            MERGE (t1)-[:JOINS_WITH]->(t2)\\n                            MERGE (t2)-[:JOINS_WITH]->(t1)\\n                            \"\"\",\\n                            db_id=db_id,\\n                            t1_id=src_table_id,\\n                            t2_id=dst_table_id,\\n                        )\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3: BUILD VECTOR INDEX OVER SCHEMA TEXT\n",
        "# ============================================================\n",
        "\n",
        "@dataclass\n",
        "class SchemaNodeMeta:\n",
        "    node_type: str  # \"TABLE\" or \"COLUMN\"\n",
        "    db_id: str\n",
        "    table_id: Optional[int] = None\n",
        "    col_id: Optional[int] = None\n",
        "    table_name: Optional[str] = None\n",
        "    column_name: Optional[str] = None\n",
        "\n",
        "class SchemaVectorIndex:\n",
        "    \"\"\"\n",
        "    Global vector index over:\n",
        "        - table-level texts (TABLE nodes)\n",
        "        - column-level texts (COLUMN nodes)\n",
        "\n",
        "    For query-time, we can filter hits by db_id if needed.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_model_name: str = EMBEDDING_MODEL_NAME):\n",
        "        self.model = SentenceTransformer(embedding_model_name)\n",
        "        self.index: Optional[faiss.IndexFlatIP] = None\n",
        "        self.metas: List[SchemaNodeMeta] = []\n",
        "        self.embeddings: Optional[np.ndarray] = None\n",
        "\n",
        "    def _build_node_texts(self, db_schemas: Dict[str, DatabaseSchema]) -> Tuple[List[str], List[SchemaNodeMeta]]:\n",
        "        texts: List[str] = []\n",
        "        metas: List[SchemaNodeMeta] = []\n",
        "\n",
        "        for db_id, db_schema in db_schemas.items():\n",
        "            for table in db_schema.tables.values():\n",
        "                # TABLE text representation\n",
        "                table_text = f\"table {table.name}\"\n",
        "                texts.append(table_text)\n",
        "                metas.append(\n",
        "                    SchemaNodeMeta(\n",
        "                        node_type=\"TABLE\",\n",
        "                        db_id=db_id,\n",
        "                        table_id=table.table_id,\n",
        "                        table_name=table.name,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                # COLUMN text representation\n",
        "                for col in table.columns:\n",
        "                    col_text = f\"column {table.name}.{col.name} of type {col.col_type}\"\n",
        "                    texts.append(col_text)\n",
        "                    metas.append(\n",
        "                        SchemaNodeMeta(\n",
        "                            node_type=\"COLUMN\",\n",
        "                            db_id=db_id,\n",
        "                            table_id=table.table_id,\n",
        "                            col_id=col.col_id,\n",
        "                            table_name=table.name,\n",
        "                            column_name=col.name,\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "        return texts, metas\n",
        "\n",
        "    def build_from_schemas(self, db_schemas: Dict[str, DatabaseSchema]):\n",
        "        texts, metas = self._build_node_texts(db_schemas)\n",
        "        print(f\"Building embeddings for {len(texts)} schema nodes...\")\n",
        "        emb = self.model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "        # Normalize embeddings for cosine similarity via inner product\n",
        "        faiss.normalize_L2(emb)\n",
        "        dim = emb.shape[1]\n",
        "        index = faiss.IndexFlatIP(dim)\n",
        "        index.add(emb.astype(np.float32))\n",
        "\n",
        "        self.index = index\n",
        "        self.embeddings = emb\n",
        "        self.metas = metas\n",
        "\n",
        "    def query(\n",
        "        self,\n",
        "        query_text: str,\n",
        "        top_k: int = 20,\n",
        "        db_id: Optional[str] = None,\n",
        "        search_k: int = 100,\n",
        "    ) -> List[Tuple[SchemaNodeMeta, float]]:\n",
        "        \"\"\"\n",
        "        Perform semantic search over schema nodes.\n",
        "        If db_id is given, we filter hits to that db.\n",
        "        \"\"\"\n",
        "        if self.index is None:\n",
        "            raise RuntimeError(\"Index not built. Call build_from_schemas() first.\")\n",
        "\n",
        "        q_emb = self.model.encode([query_text], convert_to_numpy=True)\n",
        "        faiss.normalize_L2(q_emb)\n",
        "        # Search more than top_k so we can filter by db_id\n",
        "        search_k = max(search_k, top_k)\n",
        "        D, I = self.index.search(q_emb.astype(np.float32), search_k)\n",
        "        scores = D[0]\n",
        "        indices = I[0]\n",
        "\n",
        "        results: List[Tuple[SchemaNodeMeta, float]] = []\n",
        "        for idx, score in zip(indices, scores):\n",
        "            if idx < 0:\n",
        "                continue\n",
        "            meta = self.metas[idx]\n",
        "            if db_id is not None and meta.db_id != db_id:\n",
        "                continue\n",
        "            results.append((meta, float(score)))\n",
        "            if len(results) >= top_k:\n",
        "                break\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "p67IbZzEemQb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_schema_context(\n",
        "    db_schema: DatabaseSchema,\n",
        "    matches: List[Tuple[SchemaNodeMeta, float]],\n",
        "    max_tables: int = 4,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Build textual schema context for LLM from:\n",
        "      - relevant tables/columns (from vector hits)\n",
        "      - PK/FK info\n",
        "      - join relations\n",
        "\n",
        "    Uses ONLY canonical SQL names via orig_name.\n",
        "    This ensures TRC generation is safe, consistent, and compiler-friendly.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Collect relevant table IDs\n",
        "    table_ids = []\n",
        "    for meta, score in matches:\n",
        "        if meta.table_id is None:\n",
        "            continue\n",
        "        if meta.table_id not in table_ids:\n",
        "            table_ids.append(meta.table_id)\n",
        "        if len(table_ids) >= max_tables:\n",
        "            break\n",
        "\n",
        "    lines = []\n",
        "    lines.append(\"SCHEMA CONTEXT START\")\n",
        "    lines.append(f\"Database: {db_schema.db_id}\")\n",
        "    lines.append(\"\")\n",
        "\n",
        "    # 2) Build canonical schema context\n",
        "    for table_id in table_ids:\n",
        "        table = db_schema.tables[table_id]\n",
        "\n",
        "        # Use canonical name\n",
        "        table_name = table.orig_name\n",
        "        lines.append(f\"Table: {table_name}\")\n",
        "\n",
        "        # Columns (canonical names)\n",
        "        col_parts = []\n",
        "        for col in table.columns:\n",
        "            col_parts.append(f\"{col.orig_name} ({col.col_type})\")\n",
        "        lines.append(\"  Columns: \" + \", \".join(col_parts))\n",
        "\n",
        "        # Primary keys\n",
        "        pk_cols = [db_schema.columns[pk_id].orig_name for pk_id in table.primary_keys]\n",
        "        if pk_cols:\n",
        "            lines.append(\"  Primary keys: \" + \", \".join(pk_cols))\n",
        "\n",
        "        # Foreign keys (canonical)\n",
        "        fk_descs = []\n",
        "        for src_col_id, dst_col_id in table.foreign_keys:\n",
        "            src_col = db_schema.columns[src_col_id]\n",
        "            dst_col = db_schema.columns[dst_col_id]\n",
        "            src_table = db_schema.tables[src_col.table_id]\n",
        "            dst_table = db_schema.tables[dst_col.table_id]\n",
        "\n",
        "            fk_descs.append(\n",
        "            f\"[Foreign Key REFERENCES: {dst_table.orig_name}.{dst_col.orig_name}]\"\n",
        "            )\n",
        "\n",
        "        if fk_descs:\n",
        "            lines.append(\"  Foreign keys:\")\n",
        "            for fk in fk_descs:\n",
        "                lines.append(f\"    - {fk}\")\n",
        "\n",
        "        # Join partners (canonical)\n",
        "        join_partners = set()\n",
        "\n",
        "        # Outgoing FKs\n",
        "        for src_col_id, dst_col_id in table.foreign_keys:\n",
        "            dst_col = db_schema.columns[dst_col_id]\n",
        "            dst_table = db_schema.tables[dst_col.table_id]\n",
        "            join_partners.add(dst_table.orig_name)\n",
        "\n",
        "        # Incoming FKs\n",
        "        for other_table in db_schema.tables.values():\n",
        "            if other_table.table_id == table.table_id:\n",
        "                continue\n",
        "\n",
        "            for src_col_id, dst_col_id in other_table.foreign_keys:\n",
        "                dst_col = db_schema.columns[dst_col_id]\n",
        "                dst_table = db_schema.tables[dst_col.table_id]\n",
        "\n",
        "                if dst_table.table_id == table.table_id:\n",
        "                    join_partners.add(other_table.orig_name)\n",
        "\n",
        "        lines.append(\"\")\n",
        "\n",
        "    lines.append(\"SCHEMA CONTEXT END\")\n",
        "    return \"\\n\".join(lines)"
      ],
      "metadata": {
        "id": "bTxZhjSejEj8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "\n",
        "class TextToTRCGenerator:\n",
        "    def __init__(self, model_name: str = \"llama-3.1-8b-instant\"):\n",
        "        self.model_name = model_name\n",
        "\n",
        "        groq_api_key = userdata.get('GROQ_API_KEY3')\n",
        "        if not groq_api_key:\n",
        "            raise ValueError(\"GROQ_API_KEY not found in Colab secrets. Please add it.\")\n",
        "\n",
        "        self.client = Groq(api_key=groq_api_key)\n",
        "\n",
        "\n",
        "    # ============================================================\n",
        "    # Few Shot Examples (unchanged)\n",
        "    # ============================================================\n",
        "    @staticmethod\n",
        "    def few_shot_examples() -> str:\n",
        "        examples = []\n",
        "\n",
        "        examples.append(\n",
        "        \"\"\"Example 1\n",
        "\n",
        "    == Vector Matches in Schema ==\n",
        "    VECTOR MATCHES BASED ON SEMANTICS:\n",
        "    - table: stadium (db_id: concert_singer)\n",
        "    - column: capacity (table: stadium, db_id: concert_singer)\n",
        "    - column: highest (table: stadium, db_id: concert_singer)\n",
        "    - column: lowest (table: stadium, db_id: concert_singer)\n",
        "\n",
        "    SCHEMA CONTEXT START\n",
        "    Database: concert_singer\n",
        "\n",
        "    Table: stadium\n",
        "      Columns: stadium_id (number), name (text), capacity (number), highest (number), lowest (number), average (number)\n",
        "      Primary keys: stadium_id\n",
        "\n",
        "    Table: singer\n",
        "      Columns: singer_id (number), name (text), country (text), song_name (text), song_release_year (number), age (number), is_male (others)\n",
        "      Primary keys: singer_id\n",
        "\n",
        "    SCHEMA CONTEXT END\n",
        "\n",
        "    Question:\n",
        "    \"List all stadium names with highest capacity above 35000 and lowest capacity below 8000.\"\n",
        "\n",
        "    TRC:\n",
        "    { stadium.name | stadium AND stadium.highest > 35000 AND stadium.lowest < 8000 }\n",
        "    \"\"\"\n",
        "        )\n",
        "\n",
        "        examples.append(\n",
        "    \"\"\"Example 2\n",
        "\n",
        "== Vector Matches in Schema ==\n",
        "VECTOR MATCHES BASED ON SEMANTICS:\n",
        "- table: singer (db_id: concert_singer)\n",
        "- column: name (table: singer, db_id: concert_singer)\n",
        "- table: stadium (db_id: concert_singer)\n",
        "- column: name (table: stadium, db_id: concert_singer)\n",
        "\n",
        "SCHEMA CONTEXT START\n",
        "Database: concert_singer\n",
        "\n",
        "Table: singer\n",
        "  Columns: singer_id (number), name (text), country (text), song_name (text), song_release_year (number), age (number), is_male (others)\n",
        "  Primary keys: singer_id\n",
        "\n",
        "Table: stadium\n",
        "  Columns: stadium_id (number), name (text), capacity (number), highest (number), lowest (number), average (number)\n",
        "  Primary keys: stadium_id\n",
        "\n",
        "SCHEMA CONTEXT END\n",
        "\n",
        "Question:\n",
        "\"List the names of singers and the names of stadiums.\"\n",
        "\n",
        "TRC:\n",
        "{ singer.name, stadium.name | singer AND stadium }\n",
        "\"\"\"\n",
        "        )\n",
        "\n",
        "        return \"\\n\".join(examples)\n",
        "\n",
        "\n",
        "    # ============================================================\n",
        "    # VERY STRICT PROMPT BUILDER\n",
        "    # ============================================================\n",
        "    def build_prompt(self, schema_context: str, question: str) -> str:\n",
        "        \"\"\"\n",
        "        Construct an extremely strict prompt specifically designed\n",
        "        to avoid hallucinations and produce ONLY canonical TRC.\n",
        "        \"\"\"\n",
        "        prompt_parts = []\n",
        "\n",
        "        # System-level safety rules\n",
        "        prompt_parts.append(\n",
        "            \"You are a deterministic database logic engine that outputs ONLY Tuple Relational Calculus (TRC).\\n\"\n",
        "            \"IMPORTANT RULES FOR SQL GENERATION:\\n\"\n",
        "            \"1. The NL query decides which tables are needed — NOT the schema context.\\n \"\n",
        "            \"2. Use ONLY the tables that are logically required to answer the question.\\n\"\n",
        "            \"3. If all needed information comes from a single table, produce a single-table SQL query.\\n\"\n",
        "            \"4. Do NOT add joins unless the question requires linking information across tables.\\n\"\n",
        "            \"5. If multiple tables appear in the TRC but no linking condition is required, treat it as independent filtering, not a join.\\n\"\n",
        "            \"6. Use foreign keys ONLY when the question explicitly asks to connect entities.\\n\"\n",
        "            \"7. NEVER invent columns or tables not present in the schema.\\n\"\n",
        "            \"8. ABSOLUTELY NO explanations, English sentences, or commentary.\\n\"\n",
        "            \"\\n\"\n",
        "        )\n",
        "\n",
        "        # Provide few-shot examples\n",
        "        prompt_parts.append(\"[FEW-SHOT EXAMPLES]\")\n",
        "        prompt_parts.append(self.few_shot_examples())\n",
        "\n",
        "        # Provide schema context\n",
        "        prompt_parts.append(\"\\n[SCHEMA CONTEXT]\")\n",
        "        prompt_parts.append(schema_context)\n",
        "\n",
        "        # Provide question\n",
        "        prompt_parts.append(f\"\\n[QUESTION]\\n{question}\\n\")\n",
        "\n",
        "        return \"\\n\".join(prompt_parts)\n",
        "\n",
        "\n",
        "    # ============================================================\n",
        "    # CORE LLM CALL\n",
        "    # ============================================================\n",
        "    def generate_trc(self, schema_context: str, question: str, max_new_tokens: int = 512) -> str:\n",
        "        prompt = self.build_prompt(schema_context, question)\n",
        "\n",
        "        print(\"\\nComplete INPUT PROMPT\\n\\n\",prompt)\n",
        "\n",
        "        completion = self.client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You must output ONLY raw TRC. No other text allowed.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "            temperature=0.0,      # deterministic\n",
        "            max_tokens=max_new_tokens,\n",
        "            top_p=1,\n",
        "            stream=False\n",
        "        )\n",
        "\n",
        "        return completion.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "_R2cAxwqpa4C"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 6: GLUE IT TOGETHER – END-TO-END CALL\n",
        "# ============================================================\n",
        "\n",
        "class Text2TRCPipeline:\n",
        "    def __init__( self, tables_json_path: str = TABLES_JSON_PATH, neo4j_uri: str = NEO4J_URI, neo4j_user: str = NEO4J_USER, neo4j_password: str = NEO4J_PASSWORD):\n",
        "        \"\"\"\n",
        "        Loads Spider-style schema, builds vector index, and initializes TRC generator.\n",
        "        No Neo4j functionality remains.\n",
        "        \"\"\"\n",
        "\n",
        "        # 1) Load Spider/SParC schema JSON\n",
        "        print(\"Loading Spider/SParC-style tables.json...\")\n",
        "        self.db_schemas = load_spider_like_tables_json(tables_json_path)\n",
        "\n",
        "        # 2) SKIP Neo4j schema graph\n",
        "        # (All Neo4j functions safely removed)\n",
        "\n",
        "        # 3) Build vector index\n",
        "        print(\"Building schema vector index (embeddings)...\")\n",
        "        self.vector_index = SchemaVectorIndex(EMBEDDING_MODEL_NAME)\n",
        "        self.vector_index.build_from_schemas(self.db_schemas)\n",
        "\n",
        "        # 4) LLM for Text → TRC conversion\n",
        "        print(\"Initializing Groq client for TRC prompting...\")\n",
        "        self.trc_generator = TextToTRCGenerator(\"llama-3.1-8b-instant\")\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"No Neo4j, nothing to close.\"\"\"\n",
        "        pass\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # Helper: Convert Spider tables.json schema → TRC-SQL schema dict\n",
        "    # --------------------------------------------------------\n",
        "    def convert_spider_schema(self, db_schema):\n",
        "      \"\"\"\n",
        "      Convert DatabaseSchema object into the format needed by\n",
        "      the TRC→SQL compiler:\n",
        "\n",
        "          {\n",
        "              \"table_name\": [\"col1\", \"col2\", ...],\n",
        "              ...\n",
        "          }\n",
        "      \"\"\"\n",
        "\n",
        "      schema_dict = {}\n",
        "\n",
        "      for table_id, table_obj in db_schema.tables.items():\n",
        "          table_name = table_obj.orig_name.lower()   # ✔ snake_case canonical name\n",
        "\n",
        "          column_names = [col.orig_name.lower() for col in table_obj.columns]\n",
        "\n",
        "          schema_dict[table_name] = column_names\n",
        "\n",
        "      return schema_dict\n",
        "\n",
        "    def convert_spider_fk_map(self, db_schema):\n",
        "      fk_map = []\n",
        "      for table in db_schema.tables.values():\n",
        "          for (src_col_id, dst_col_id) in table.foreign_keys:\n",
        "              src_col = db_schema.columns[src_col_id]\n",
        "              dst_col = db_schema.columns[dst_col_id]\n",
        "\n",
        "              src_table = db_schema.tables[src_col.table_id]\n",
        "              dst_table = db_schema.tables[dst_col.table_id]\n",
        "\n",
        "              fk_map.append((\n",
        "                  src_table.orig_name.lower(), src_col.orig_name.lower(),\n",
        "                  dst_table.orig_name.lower(), dst_col.orig_name.lower()\n",
        "              ))\n",
        "      return fk_map\n",
        "\n",
        "    # --------------------------------------------------------\n",
        "    # MAIN INFERENCE\n",
        "    # --------------------------------------------------------\n",
        "    def infer_trc_for_query(\n",
        "        self,\n",
        "        question: str,\n",
        "        db_id: str,\n",
        "        top_k_schema_nodes: int = 20,\n",
        "        max_tables_in_context: int = 4,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Main function: Text → TRC\n",
        "\n",
        "        Returns:\n",
        "            {\n",
        "                \"schema_matches\": [...],\n",
        "                \"schema_context\": \"...\",\n",
        "                \"trc\": \"...\",\n",
        "                \"schema_for_sql_compiler\": {...}   # ADDED\n",
        "            }\n",
        "        \"\"\"\n",
        "\n",
        "        # Validate db_id\n",
        "        if db_id not in self.db_schemas:\n",
        "            raise ValueError(f\"Unknown db_id: {db_id}\")\n",
        "\n",
        "        db_schema = self.db_schemas[db_id]\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # 1) Semantic retrieval over schema (vector search)\n",
        "        # ----------------------------------------------------\n",
        "        matches = self.vector_index.query(\n",
        "            query_text=question,\n",
        "            top_k=top_k_schema_nodes,\n",
        "            db_id=db_id,\n",
        "        )\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # 2) Build schema context for the LLM prompt\n",
        "        # ----------------------------------------------------\n",
        "        schema_context = build_schema_context(\n",
        "            db_schema=db_schema,\n",
        "            matches=matches,\n",
        "            max_tables=max_tables_in_context,\n",
        "        )\n",
        "\n",
        "        # Create a compact match summary for prompt\n",
        "        match_summary_for_prompt = []\n",
        "        for meta, score in matches:\n",
        "            if meta.node_type == \"TABLE\":\n",
        "                match_summary_for_prompt.append(\n",
        "                    f\"- table: {meta.table_name} (db_id: {meta.db_id})\"\n",
        "                )\n",
        "            else:\n",
        "                match_summary_for_prompt.append(\n",
        "                    f\"- column: {meta.column_name} (table: {meta.table_name}, db_id: {meta.db_id})\"\n",
        "                )\n",
        "\n",
        "        vector_match_text = \"VECTOR MATCHES BASED ON SEMANTICS:\\n\" + \"\\n\".join(match_summary_for_prompt)\n",
        "\n",
        "        # Full prompt context\n",
        "        full_context = vector_match_text + \"\\n\\n\" +schema_context\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # 3) LLM generates the TRC\n",
        "        # ----------------------------------------------------\n",
        "        trc = self.trc_generator.generate_trc(\n",
        "            schema_context=full_context,\n",
        "            question=question\n",
        "        )\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # 4) Build debugging metadata\n",
        "        # ----------------------------------------------------\n",
        "        match_summary = [\n",
        "            {\n",
        "                \"node_type\": meta.node_type,\n",
        "                \"db_id\": meta.db_id,\n",
        "                \"table_id\": meta.table_id,\n",
        "                \"col_id\": meta.col_id,\n",
        "                \"table_name\": meta.table_name,\n",
        "                \"column_name\": meta.column_name,\n",
        "                \"score\": score,\n",
        "            }\n",
        "            for meta, score in matches\n",
        "        ]\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # 5) Convert schema for TRC→SQL compiler\n",
        "        # ----------------------------------------------------\n",
        "        converted_schema = self.convert_spider_schema(db_schema)\n",
        "\n",
        "        # ----------------------------------------------------\n",
        "        # 6) FK Map\n",
        "        # ----------------------------------------------------\n",
        "        fk_map = self.convert_spider_fk_map(db_schema)\n",
        "        # ----------------------------------------------------\n",
        "        # 7) Final return\n",
        "        # ----------------------------------------------------\n",
        "        return {\n",
        "            \"schema_matches\": match_summary,\n",
        "            \"schema_context\": schema_context,\n",
        "            \"trc\": trc,\n",
        "            \"schema_for_sql_compiler\": converted_schema,  # <--- ADDED\n",
        "            \"vector_match_text\": vector_match_text,\n",
        "            \"fk_map\": fk_map,\n",
        "            \"full_context\": full_context\n",
        "        }"
      ],
      "metadata": {
        "id": "f6R72r4IP0M3"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# EXAMPLE USAGE\n",
        "# ============================================================\n",
        "from groq import Groq\n",
        "\n",
        "trc2sql_client = Groq(api_key=userdata.get('GROQ_API_KEY3'))\n",
        "\n",
        "\"\"\"\n",
        "    Example: run a single Text->TRC inference on a SParC/Spider db.\n",
        "    \"\"\"\n",
        "\n",
        "pipeline = Text2TRCPipeline(\n",
        "        tables_json_path=TABLES_JSON_PATH,\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "73a4e2762ee4448b8a5feb0b63918970",
            "6667b5ffb7ae4a14bfe8b2311890742a",
            "d919a2f84cf64abdbad57115cb2ac630",
            "411ca5d60e3d4a4e8337b2c931482a2b",
            "7fb8d4066ddd48e38abc8011d8746e8e",
            "1b792570aea94912a416a3f99dd0110b",
            "c3a9a38007154ab09d122546993ddfee",
            "0b9315e182e049c3ac1d508a7118bc85",
            "2fcc45fa3f9a4949abe86faf9785bb64",
            "63e1c8a5ddb843d1aabe3b74035077b6",
            "aad41fcd3976479389812ec7d28e7140"
          ]
        },
        "id": "bT8nY-3L_eqK",
        "outputId": "31080e70-48f8-474a-b3e2-46d2aeea61ea"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Spider/SParC-style tables.json...\n",
            "Building schema vector index (embeddings)...\n",
            "Building embeddings for 5379 schema nodes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/169 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73a4e2762ee4448b8a5feb0b63918970"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Groq client for TRC prompting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "        # Example NL question and DB\n",
        "        example_db_id = \"flight_1\"\n",
        "        example_question = \"Show the flight number and distance of all the flights.\"\n",
        "\n",
        "        # --- 1. Run TEXT → TRC ---\n",
        "        result = pipeline.infer_trc_for_query(\n",
        "            question=example_question,\n",
        "            db_id=example_db_id,\n",
        "            top_k_schema_nodes=20,\n",
        "            max_tables_in_context=4,\n",
        "        )\n",
        "        \"\"\"\n",
        "        print(\"\\n=== Vector Matches in Schema ===\")\n",
        "        print(result[\"vector_match_text\"])\n",
        "\n",
        "\n",
        "        print(\"\\n=== SCHEMA CONTEXT FED TO LLM ===\")\n",
        "        print(result[\"schema_context\"])\n",
        "\n",
        "        print(\"output\")\n",
        "        print(result[\"full_context\"])\n",
        "        \"\"\"\n",
        "        print(\"\\n=== GENERATED TRC ===\")\n",
        "        print(result[\"trc\"])\n",
        "\n",
        "\n",
        "        # ============================================================\n",
        "        # --- 2. Run TRC → SQL using Groq LLaMA-3.1-8B (NEW)\n",
        "        # ============================================================\n",
        "        system_prompt = \"\"\"\n",
        "You are a strict TRC-to-SQL compiler.\n",
        "RULES:\n",
        "1. Follow the TRC properly and answer with the right SQL. The TRC determines the SQL not the schema.\n",
        "2. DO NOT invent tables or columns.\n",
        "3.Use ONLY the tables necessary to express the meaning of the question.\n",
        "4.If the question can be answered from a single table, use that table alone.\n",
        "5.Do not include unrelated tables, even if they appear in the schema context.\n",
        "6. Output ONLY valid SQL, no explanations.\n",
        "\"\"\"\n",
        "\n",
        "        user_prompt = f\"\"\"\n",
        "Vector Matches in SCHEMA CONTEXT:\n",
        "{result['vector_match_text']}\n",
        "\n",
        "Below are examples showing how TRC must be converted into valid SQL.\n",
        "\n",
        "        Example 1\n",
        "        Schema:\n",
        "          table stadium(stadium_id, name, capacity, highest, lowest, average)\n",
        "          table singer(singer_id, name, country)\n",
        "          table concert(concert_id, stadium_id, concert_name)\n",
        "\n",
        "        TRC:\n",
        "        {{ stadium.name | stadium AND stadium.highest > 35000 AND stadium.lowest < 8000 }}\n",
        "\n",
        "        SQL OUTPUT:\n",
        "        SELECT name\n",
        "        FROM stadium\n",
        "        WHERE highest > 35000\n",
        "          AND lowest < 8000;\n",
        "\n",
        "        EXAMPLE 2:\n",
        "        Schema:\n",
        "          table stadium(stadium_id, location, name, capacity, highest, lowest, average)\n",
        "          table singer(singer_id, name, country, song_name, song_release_year, age, is_male)\n",
        "          table concert(concert_id, concert_name, theme, stadium_id, year)\n",
        "          table singer_in_concert(concert_id, singer_id)\n",
        "\n",
        "        TRC:\n",
        "          {{ name | singer\n",
        "                  AND singer_in_concert\n",
        "                  AND singer_in_concert.singer_id = singer.singer_id\n",
        "                  AND singer_in_concert.concert_id = concert.concert_id\n",
        "                  AND concert.stadium_id = stadium.stadium_id\n",
        "                  AND stadium.capacity > 50000 }}\n",
        "\n",
        "        SQL OUTPUT:\n",
        "          SELECT singer.name\n",
        "          FROM singer\n",
        "          JOIN singer_in_concert\n",
        "              ON singer_in_concert.singer_id = singer.singer_id\n",
        "          JOIN concert\n",
        "              ON singer_in_concert.concert_id = concert.concert_id\n",
        "          JOIN stadium\n",
        "              ON concert.stadium_id = stadium.stadium_id\n",
        "          WHERE stadium.capacity > 50000;\n",
        "\n",
        "\n",
        "        Now convert the following TRC (for the schema above) into SQL.\n",
        "\n",
        "TRC:\n",
        "{result['trc']}\n",
        "\n",
        "Translate the TRC expression above into executable SQL.\n",
        "Output ONLY the SQL query.\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            groq_response = trc2sql_client.chat.completions.create(\n",
        "                model=\"llama-3.1-8b-instant\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": user_prompt},\n",
        "                ],\n",
        "                temperature=0.0,\n",
        "                max_tokens=300,\n",
        "            )\n",
        "            predicted_sql = groq_response.choices[0].message.content.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            predicted_sql = f\"-- GROQ SQL GENERATION ERROR: {str(e)}\"\n",
        "\n",
        "        print(\"\\n=== GENERATED SQL (Groq LLaMA 3.1 8B) ===\")\n",
        "        print(predicted_sql)\n",
        "        # ============================================================\n",
        "\n",
        "finally:\n",
        "        pipeline.close()\n"
      ],
      "metadata": {
        "id": "koAzetWCpiSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070da39d-b781-44f8-bd72-4c8bea8a248d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Complete INPUT PROMPT\n",
            "\n",
            " You are a deterministic database logic engine that outputs ONLY Tuple Relational Calculus (TRC).\n",
            "IMPORTANT RULES FOR SQL GENERATION:\n",
            "1. The NL query decides which tables are needed — NOT the schema context.\n",
            " 2. Use ONLY the tables that are logically required to answer the question.\n",
            "3. If all needed information comes from a single table, produce a single-table SQL query.\n",
            "4. Do NOT add joins unless the question requires linking information across tables.\n",
            "5. If multiple tables appear in the TRC but no linking condition is required, treat it as independent filtering, not a join.\n",
            "6. Use foreign keys ONLY when the question explicitly asks to connect entities.\n",
            "7. NEVER invent columns or tables not present in the schema.\n",
            "8. ABSOLUTELY NO explanations, English sentences, or commentary.\n",
            "\n",
            "\n",
            "[FEW-SHOT EXAMPLES]\n",
            "Example 1\n",
            "\n",
            "    == Vector Matches in Schema ==\n",
            "    VECTOR MATCHES BASED ON SEMANTICS:\n",
            "    - table: stadium (db_id: concert_singer)\n",
            "    - column: capacity (table: stadium, db_id: concert_singer)\n",
            "    - column: highest (table: stadium, db_id: concert_singer)\n",
            "    - column: lowest (table: stadium, db_id: concert_singer)\n",
            "\n",
            "    SCHEMA CONTEXT START\n",
            "    Database: concert_singer\n",
            "\n",
            "    Table: stadium\n",
            "      Columns: stadium_id (number), name (text), capacity (number), highest (number), lowest (number), average (number)\n",
            "      Primary keys: stadium_id\n",
            "\n",
            "    Table: singer\n",
            "      Columns: singer_id (number), name (text), country (text), song_name (text), song_release_year (number), age (number), is_male (others)\n",
            "      Primary keys: singer_id\n",
            "\n",
            "    SCHEMA CONTEXT END\n",
            "\n",
            "    Question:\n",
            "    \"List all stadium names with highest capacity above 35000 and lowest capacity below 8000.\"\n",
            "\n",
            "    TRC:\n",
            "    { stadium.name | stadium AND stadium.highest > 35000 AND stadium.lowest < 8000 }\n",
            "    \n",
            "Example 2\n",
            "\n",
            "== Vector Matches in Schema ==\n",
            "VECTOR MATCHES BASED ON SEMANTICS:\n",
            "- table: singer (db_id: concert_singer)\n",
            "- column: name (table: singer, db_id: concert_singer)\n",
            "- table: stadium (db_id: concert_singer)\n",
            "- column: name (table: stadium, db_id: concert_singer)\n",
            "\n",
            "SCHEMA CONTEXT START\n",
            "Database: concert_singer\n",
            "\n",
            "Table: singer\n",
            "  Columns: singer_id (number), name (text), country (text), song_name (text), song_release_year (number), age (number), is_male (others)\n",
            "  Primary keys: singer_id\n",
            "\n",
            "Table: stadium\n",
            "  Columns: stadium_id (number), name (text), capacity (number), highest (number), lowest (number), average (number)\n",
            "  Primary keys: stadium_id\n",
            "\n",
            "SCHEMA CONTEXT END\n",
            "\n",
            "Question:\n",
            "\"List the names of singers and the names of stadiums.\"\n",
            "\n",
            "TRC:\n",
            "{ singer.name, stadium.name | singer AND stadium }\n",
            "\n",
            "\n",
            "[SCHEMA CONTEXT]\n",
            "VECTOR MATCHES BASED ON SEMANTICS:\n",
            "- column: distance (table: flight, db_id: flight_1)\n",
            "- column: flight number (table: flight, db_id: flight_1)\n",
            "- column: distance (table: aircraft, db_id: flight_1)\n",
            "- column: departure date (table: flight, db_id: flight_1)\n",
            "- column: arrival date (table: flight, db_id: flight_1)\n",
            "- table: flight (db_id: flight_1)\n",
            "- column: airline id (table: flight, db_id: flight_1)\n",
            "- column: destination (table: flight, db_id: flight_1)\n",
            "- column: airline id (table: aircraft, db_id: flight_1)\n",
            "- column: price (table: flight, db_id: flight_1)\n",
            "- table: aircraft (db_id: flight_1)\n",
            "- column: name (table: aircraft, db_id: flight_1)\n",
            "\n",
            "SCHEMA CONTEXT START\n",
            "Database: flight_1\n",
            "\n",
            "Table: flight\n",
            "  Columns: flno (number), origin (text), destination (text), distance (number), departure_date (time), arrival_date (time), price (number), aid (number)\n",
            "  Primary keys: flno\n",
            "  Foreign keys:\n",
            "    - [Foreign Key REFERENCES: aircraft.aid]\n",
            "\n",
            "Table: aircraft\n",
            "  Columns: aid (number), name (text), distance (number)\n",
            "  Primary keys: aid\n",
            "\n",
            "SCHEMA CONTEXT END\n",
            "\n",
            "[QUESTION]\n",
            "Show the flight number and distance of all the flights.\n",
            "\n",
            "\n",
            "=== GENERATED TRC ===\n",
            "{ flight.flno, flight.distance | flight }\n",
            "\n",
            "=== GENERATED SQL (Groq LLaMA 3.1 8B) ===\n",
            "SELECT flno, distance\n",
            "FROM flight;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating SPARC dataset with dialogue history and visualizing the results**"
      ],
      "metadata": {
        "id": "dbj-SNhfsd6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Path to SParC train/dev/test json\n",
        "SPARC_TRAIN_PATH = \"/content/train.json\"   # change if needed\n",
        "\n",
        "# Output file for TRC predictions\n",
        "OUTPUT_PATH = \"/content/sparc_trc_predictions.json\"\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# LOAD DATASET\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "with open(SPARC_TRAIN_PATH, \"r\") as f:\n",
        "    sparc_data = json.load(f)\n",
        "\n",
        "# Take only 5 interactions\n",
        "import random\n",
        "\n",
        "print(f\"Using {len(sparc_data)} interactions for evaluation.\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# INITIALIZE PIPELINE\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "pipeline = Text2TRCPipeline(\n",
        "    tables_json_path=TABLES_JSON_PATH,\n",
        "    neo4j_uri=NEO4J_URI,\n",
        "    neo4j_user=NEO4J_USER,\n",
        "    neo4j_password=NEO4J_PASSWORD,\n",
        ")\n",
        "\n",
        "print(\"Pipeline initialized.\")\n"
      ],
      "metadata": {
        "id": "8d5A5O97slNT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "fa77dcb1d570472b8741aac08a5cd5be",
            "fe6379e0c59f464e9e61421ac0036245",
            "21f05c9243b340a283c68b5c44ed32e5",
            "a50180e2ed5e422987930592c01542dc",
            "d8e82091c4fd49eeb4b16818d8d640aa",
            "f9aa61c61ddc4b55910f3e7cefb7619c",
            "5b78530836b54fa7bda2cc5d3868073d",
            "ecdf64d7faf94cbb9bdef16a0943fbab",
            "10ab10ba7cc945a5ad60f16fb1f6f6d5",
            "ae3a9599f91048f59e921a81ae67c241",
            "3b07e2895f794a53b00a1107a276803c"
          ]
        },
        "outputId": "0d28d3bc-e65f-4c39-d632-634617bb5b52"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 3034 interactions for evaluation.\n",
            "Loading Spider/SParC-style tables.json...\n",
            "Building schema vector index (embeddings)...\n",
            "Building embeddings for 5379 schema nodes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/169 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa77dcb1d570472b8741aac08a5cd5be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Groq client for TRC prompting...\n",
            "Pipeline initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# FUNCTION: BUILD HISTORY CONTEXT\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def build_history_context(interaction, current_turn_idx):\n",
        "    \"\"\"\n",
        "    Builds history of all previous user utterances for multi-turn SParC dialogue.\n",
        "    Returns a formatted string:\n",
        "\n",
        "    HISTORY:\n",
        "    User: ...\n",
        "    User: ...\n",
        "    \"\"\"\n",
        "    if current_turn_idx == 0:\n",
        "        return \"\"  # No history for first turn\n",
        "\n",
        "    history_lines = [\"HISTORY CONTEXT:\"]\n",
        "    for i in range(current_turn_idx):\n",
        "        prev_utt = interaction[\"interaction\"][i][\"utterance\"]\n",
        "        history_lines.append(f\"User: {prev_utt}\")\n",
        "\n",
        "    return \"\\n\".join(history_lines) + \"\\n\\n\"\n"
      ],
      "metadata": {
        "id": "m7rLLMdOsmxm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# RUN EVALUATION OVER ENTIRE SParC TRAIN SET\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "predictions = []  # store everything\n",
        "\n",
        "for interaction in tqdm(sparc_data, desc=\"Processing SParC interactions\"):\n",
        "\n",
        "    db_id = interaction[\"database_id\"]\n",
        "    turns = interaction[\"interaction\"]\n",
        "\n",
        "    for turn_idx, turn in enumerate(turns):\n",
        "\n",
        "        utterance = turn[\"utterance\"]\n",
        "\n",
        "        # ---- Build history ----\n",
        "        history_context = build_history_context(interaction, turn_idx)\n",
        "\n",
        "        # ---- Merge history + current question ----\n",
        "        llm_input_question = history_context + utterance\n",
        "\n",
        "        # ---- Run Text->TRC pipeline ----\n",
        "        result = pipeline.infer_trc_for_query(\n",
        "            question=llm_input_question,\n",
        "            db_id=db_id,\n",
        "            top_k_schema_nodes=20,\n",
        "            max_tables_in_context=4,\n",
        "        )\n",
        "\n",
        "        # ------------------------------------------------------------\n",
        "        # NEW: SQL generation using Groq LLaMA-3.1-8B\n",
        "        # ------------------------------------------------------------\n",
        "\n",
        "        system_prompt = \"\"\"\n",
        "        You are a strict TRC-to-SQL compiler.\n",
        "        RULES:\n",
        "        1. Follow the TRC properly and answer with the right SQL. The TRC determines the SQL not the schema.\n",
        "        2. DO NOT invent tables or columns.\n",
        "        3. Use ONLY the tables necessary to express the meaning of the question.\n",
        "        4. If the question can be answered from a single table, use that table alone.\n",
        "        5. Do not include unrelated tables, even if they appear in the schema context.\n",
        "        6. Output ONLY valid SQL, no explanations.\n",
        "        \"\"\"\n",
        "\n",
        "        user_prompt = f\"\"\"\n",
        "        Vector Matches in SCHEMA CONTEXT:\n",
        "        {result['vector_match_text']}\n",
        "\n",
        "        Below are examples showing how TRC must be converted into valid SQL.\n",
        "\n",
        "        Example 1\n",
        "        Schema:\n",
        "          table stadium(stadium_id, name, capacity, highest, lowest, average)\n",
        "          table singer(singer_id, name, country)\n",
        "          table concert(concert_id, stadium_id, concert_name)\n",
        "\n",
        "        TRC:\n",
        "        {{ stadium.name | stadium AND stadium.highest > 35000 AND stadium.lowest < 8000 }}\n",
        "\n",
        "        SQL:\n",
        "        SELECT name\n",
        "        FROM stadium\n",
        "        WHERE highest > 35000\n",
        "          AND lowest < 8000;\n",
        "\n",
        "        EXAMPLE 2:\n",
        "        Schema:\n",
        "          table stadium(stadium_id, location, name, capacity, highest, lowest, average)\n",
        "          table singer(singer_id, name, country, song_name, song_release_year, age, is_male)\n",
        "          table concert(concert_id, concert_name, theme, stadium_id, year)\n",
        "          table singer_in_concert(concert_id, singer_id)\n",
        "\n",
        "        TRC:\n",
        "          {{ name | singer\n",
        "                  AND singer_in_concert\n",
        "                  AND singer_in_concert.singer_id = singer.singer_id\n",
        "                  AND singer_in_concert.concert_id = concert.concert_id\n",
        "                  AND concert.stadium_id = stadium.stadium_id\n",
        "                  AND stadium.capacity > 50000 }}\n",
        "\n",
        "        SQL:\n",
        "          SELECT singer.name\n",
        "          FROM singer\n",
        "          JOIN singer_in_concert\n",
        "              ON singer_in_concert.singer_id = singer.singer_id\n",
        "          JOIN concert\n",
        "              ON singer_in_concert.concert_id = concert.concert_id\n",
        "          JOIN stadium\n",
        "              ON concert.stadium_id = stadium.stadium_id\n",
        "          WHERE stadium.capacity > 50000;\n",
        "\n",
        "        Tuple Relational Calculus (TRC):\n",
        "        {result['trc']}\n",
        "\n",
        "        Now convert the following TRC (for the schema above) into SQL. Output Only SQL.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            groq_response = trc2sql_client.chat.completions.create(\n",
        "                model=\"llama-3.1-8b-instant\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": user_prompt},\n",
        "                ],\n",
        "                temperature=0.0,\n",
        "                max_tokens=300,\n",
        "            )\n",
        "            predicted_sql = groq_response.choices[0].message.content.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            predicted_sql = f\"-- GROQ SQL GENERATION ERROR: {str(e)}\"\n",
        "\n",
        "\n",
        "        # ---- Store result ----\n",
        "        predictions.append({\n",
        "            \"db_id\": db_id,\n",
        "            \"turn_index\": turn_idx,\n",
        "            \"utterance\": utterance,\n",
        "            \"history_used\": history_context,\n",
        "            \"schema_matches\": result[\"schema_matches\"],\n",
        "            \"schema_context\": result[\"schema_context\"],\n",
        "            \"predicted_trc\": result[\"trc\"],\n",
        "            \"predicted_sql\": predicted_sql,     # <-- NEW KEY ADDED\n",
        "            \"gold_sql\": turn[\"query\"],          # Ground truth SQL\n",
        "        })\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# SAVE RESULTS\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "with open(OUTPUT_PATH, \"w\") as f:\n",
        "    json.dump(predictions, f, indent=2)\n",
        "\n",
        "print(f\"Saved {len(predictions)} predictions to {OUTPUT_PATH}\")\n"
      ],
      "metadata": {
        "id": "i9Noh2YRsjUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(OUTPUT_PATH, \"w\") as f:\n",
        "    json.dump(predictions, f, indent=2)\n",
        "\n",
        "print(f\"Saved {len(predictions)} predictions to {OUTPUT_PATH}\")"
      ],
      "metadata": {
        "id": "8iisbvCQ1a7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe11127-cdd5-4a00-b7ee-e421f3e9f237"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 46 predictions to /content/sparc_trc_predictions.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eVa9DiIMqNdd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}